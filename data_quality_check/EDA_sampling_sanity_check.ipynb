{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sampling Notebook\n",
                "---\n",
                "## Setup imports and initial comment retrieval"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pymongo\n",
                "import random\n",
                "import pandas as pd\n",
                "import configparser\n",
                "from pathlib import Path\n",
                "from typing import Any\n",
                "import re\n",
                "from selenium import webdriver\n",
                "from webdriver_manager.chrome import ChromeDriverManager\n",
                "from selenium.webdriver.chrome.service import Service\n",
                "from selenium.webdriver.common.by import By\n",
                "from selenium.webdriver.support.ui import WebDriverWait\n",
                "from selenium.webdriver.support import expected_conditions as EC\n",
                "from bs4 import BeautifulSoup\n",
                "\n",
                "# check average length of content\n",
                "# check min and max lengths of content \n",
                "\n",
                "config = configparser.RawConfigParser()\n",
                "config.read(Path(\"../application.properties\"))\n",
                "\n",
                "def get_mongoclient(config: configparser.RawConfigParser) -> pymongo.MongoClient:\n",
                "\n",
                "    user = config.get('DatabaseSection', 'mongodb.user')\n",
                "    password = config.get('DatabaseSection', 'mongodb.password')\n",
                "    hostname = config.get('DatabaseSection', 'mongodb.hostname')\n",
                "    port = config.get('DatabaseSection', 'mongodb.port')\n",
                "    options = config.get('DatabaseSection', 'mongodb.options')\n",
                "\n",
                "    conn_str = f\"mongodb://{user}:{password}@{hostname}:{port}/{options}\"\n",
                "\n",
                "    return pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=5000, unicode_decode_error_handler='ignore')\n",
                "\n",
                "comments_db = config.get('DatabaseSection', 'mongodb.database.comments')\n",
                "db = get_mongoclient(config=config)[comments_db]\n",
                "# pattern = re.compile('\\.java$', re.IGNORECASE)\n",
                "comments = list(db.comments_only_java.find({'filtered': False}))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "895423"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(comments)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper functions and Stratified comment sample setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "amount of project included in stratified sample: 94\n",
                        "amount of comments per project included in stratified sample:\n",
                        "PROJECT\n",
                        "activemq             3\n",
                        "airavata             3\n",
                        "archiva              3\n",
                        "avro                 3\n",
                        "bigtop               3\n",
                        "                    ..\n",
                        "velocity-tools       3\n",
                        "wss4j                3\n",
                        "xmlgraphics-batik    3\n",
                        "zeppelin             3\n",
                        "zookeeper            3\n",
                        "Name: PROJECT, Length: 94, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "from typing import Callable, Dict, List\n",
                "from bs4 import Tag\n",
                "from selenium.common.exceptions import TimeoutException\n",
                "\n",
                "def sample_and_persist_df(df: pd.DataFrame, sample_size: int, path: Path) -> pd.DataFrame:\n",
                "\n",
                "    seed = 24104 \n",
                "    if sample_size == 1:\n",
                "        sample_df = df.sample(frac=1, random_state=seed).reset_index(drop = True)\n",
                "    else:\n",
                "        sample_df = df.sample(sample_size, random_state=seed)\n",
                "\n",
                "\n",
                "    sample_df.to_excel(path, index=False)\n",
                "\n",
                "    return sample_df\n",
                "\n",
                "\n",
                "def create_context_df(df_to_filter_path: Path, filter_df_path: Path, content_col_name: str, context_label: str) -> pd.DataFrame:\n",
                "\n",
                "    # TODO dont need 2 dfs! can just use 1 df and filter that one based on label!!\n",
                "\n",
                "    df_to_filter = pd.read_excel(df_to_filter_path)\n",
                "    filter_df = pd.read_excel(filter_df_path, sheet_name='Comments Labeled',\n",
                "                                        usecols=content_col_name,\n",
                "                                            na_values='',\n",
                "                                            nrows=len(df_to_filter), ).fillna('nan')\n",
                "                                            \n",
                "    df_to_filter.reset_index(drop=True, inplace=True)\n",
                "    \n",
                "    context_df = df_to_filter[filter_df.iloc[:,0].str.contains(context_label)]\n",
                "\n",
                "    # generate comment context urls\n",
                "    context_df['COMM_COMMIT_URL'] = get_commit_diff_comment_urls(\n",
                "        context_df['COMM_COMMIT_URL'].values,\n",
                "        context_df['FILE_PATH'].values,\n",
                "        context_df['HUNK_NEW_LINE'].values)\n",
                "    \n",
                "    return context_df\n",
                "\n",
                "def get_commit_diff_comment_urls(commit_urls: List[str], file_paths: List[str], line_numbs: List[int]) -> List[str]:\n",
                "    # Set the string to search for within the diff\n",
                "    comment_urls = []\n",
                "\n",
                "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
                "    \n",
                "    for idx, commit_url in enumerate(commit_urls):\n",
                "        html = ''\n",
                "        # Construct the GitHub API URL\n",
                "        driver.get(commit_url)\n",
                "\n",
                "        wait = WebDriverWait(driver, 20)\n",
                "        try:\n",
                "            end_of_file_path = \"/\" + file_paths[idx].split(\"/\")[-1]\n",
                "            element = wait.until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, end_of_file_path))) \n",
                "            html = driver.page_source\n",
                "\n",
                "            soup = BeautifulSoup(html, \"html.parser\")\n",
                "            diff_anchor = soup.find(filter_links(end_of_file_path))\n",
                "            if diff_anchor:\n",
                "                commit_url = f'{commit_url}{diff_anchor[\"href\"]}R{line_numbs[idx]}'\n",
                "            # TODO activate this else as last resort \n",
                "            # can actually be the case that file path can be found but then commit seems to be wrong so then need to have fail safe to add blob path\n",
                "            # example: https://github.com/apache/derby/commit/f16c46cbdd5be8dd9bdcee935ec1f68970146478 and ending file path: /OperatorNode.java\n",
                "            # with comment: \"No query. The SqlXmlUtil instance is still on the stack. Pop it to restore the initial state of the stack.\"\n",
                "            # else:\n",
                "            #     commit_url = f'{commit_url.replace(\"commit\", \"blob\")}/{file_paths[idx]}#L{line_numbs[idx]}'\n",
                "\n",
                "        except TimeoutException:\n",
                "            commit_url = f'{commit_url.replace(\"commit\", \"blob\")}/{file_paths[idx]}#L{line_numbs[idx]}'\n",
                "\n",
                "        comment_urls.append(commit_url)\n",
                "\n",
                "    driver.quit()\n",
                "\n",
                "    return comment_urls\n",
                "\n",
                "def filter_links(filter_text: str) -> Callable:\n",
                "    \n",
                "    def filter_links_ending_with_str(tag: Tag):\n",
                "        return tag.name == 'a' and tag.text.endswith(filter_text)\n",
                "    \n",
                "    return filter_links_ending_with_str\n",
                "\n",
                "def stratify_prop_to_project_name(df: pd.DataFrame, sample_frac: float) -> pd.DataFrame:\n",
                "   random_seed_strat = 2802234\n",
                "   df['PROJECT'].unique()[0]\n",
                "\n",
                "#    return df.sample(max(1, int(sample_frac*len(df))), random_state=random_seed_strat)\n",
                "   return df.sample(3, random_state=random_seed_strat)\n",
                "\n",
                "def get_rand_item(comments: List[Dict]) -> Dict:\n",
                "    random.seed(26225)\n",
                "    return random.sample(comments, 1)\n",
                "\n",
                "def get_comment_df(comments: Dict) -> pd.DataFrame:\n",
                "    ids = [comment_dict['_id'] for comment_dict in comments]\n",
                "    contents = [comment_dict['content'] for comment_dict in comments]\n",
                "    project_names = [comment_dict['project_name'] for comment_dict in comments]\n",
                "    comm_types = [comment_dict['type'] for comment_dict in comments]\n",
                "    comm_dates = [comment_dict['committer_date'] for comment_dict in comments]\n",
                "    comm_file_path = [comment_dict['file_path'] for comment_dict in comments]\n",
                "    comm_vcs = ['{}/commit/{}'.format(comment_dict['vcs_url'].replace('.git', ''),\n",
                "                                       comment_dict['commit_hash']) for comment_dict in comments]\n",
                "    comm_hunk_old_line = [comment_dict['hunk_old_start'] for comment_dict in comments]\n",
                "    comm_hunk_new_line = [comment_dict['hunk_new_start'] for comment_dict in comments]\n",
                "\n",
                "    return pd.DataFrame(dict(\n",
                "    ID=ids,\n",
                "    FILE_PATH=comm_file_path,\n",
                "    COMM_TYPE=comm_types,\n",
                "    COMM_DATE=comm_dates,\n",
                "    COMM_COMMIT_URL=comm_vcs,\n",
                "    HUNK_OLD_LINE=comm_hunk_old_line,\n",
                "    HUNK_NEW_LINE=comm_hunk_new_line,\n",
                "    CONTENT=contents,\n",
                "    PROJECT=project_names,\n",
                "    ))\n",
                "\n",
                "def get_strat_comment_df(comments: pd.DataFrame, sample_frac: float, seed: int) -> pd.DataFrame:\n",
                "    shuffled_df = comments.sample(frac=1, random_state=seed)\n",
                "\n",
                "    return shuffled_df.groupby('PROJECT', group_keys=False).apply(lambda x: stratify_prop_to_project_name(x, sample_frac))\n",
                "\n",
                "# statistical sample size not needed as we do not use Cohens kappa on a sample of labeled data for agreement.\n",
                "# check agreement with Cohens kappa and agreement level according to Fleiss (see duplicate SATD paper)\n",
                "# Do need to get a statistical significant proportion of sample \n",
                "\n",
                "# C.I. = 5% and confidence level 95% then sample size 384..to get a statistically sign. sample for proportion p of SATD/non-SATD\n",
                "# C.I. = 7% and confidence level 95% then sample size 196..to get a statistically sign. sample for proportion p of SATD/non-SATD\n",
                "# C.I. = 8% and confidence level 95% then sample size 150..to get a statistically sign. sample for proportion p of SATD/non-SATD \n",
                "# C.I. = 10% and confidence level 95% then sample size 96..to get a statistically sign. sample for proportion p of SATD/non-SATD \n",
                "# start with 96 and see how it goes?\n",
                "# can also compare p with proportions found in Guo et al and Maldonado datasets\n",
                "stat_sign_sample_size = 95\n",
                "\n",
                "comments_df = get_comment_df(comments)\n",
                "comments_df = comments_df.drop_duplicates(subset=['PROJECT', 'CONTENT'])\n",
                "\n",
                "# remove projects that do not have more than 2 comments\n",
                "project_freq = comments_df['PROJECT'].value_counts()\n",
                "projects = project_freq[project_freq>2]\n",
                "comments_df = comments_df[comments_df['PROJECT'].isin(projects.index)]\n",
                "\n",
                "random_seed_shuffle = 122324\n",
                "sample_frac = stat_sign_sample_size / len(comments_df)\n",
                "stratified_df = get_strat_comment_df(comments=comments_df, sample_frac=sample_frac, seed=random_seed_shuffle)\n",
                "\n",
                "\n",
                "\n",
                "strat_project_count = len(stratified_df['PROJECT'].unique())\n",
                "print(f'amount of project included in stratified sample: {strat_project_count}')\n",
                "\n",
                "count_per_project = stratified_df.groupby(['PROJECT'])['PROJECT'].count()\n",
                "print(f'amount of comments per project included in stratified sample:')\n",
                "print(count_per_project)\n",
                "\n",
                "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
                "#     display(stratified_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "282"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(stratified_df)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Persisting\n",
                "---\n",
                "## First Tutorial Sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tutorial_sample_size = 120\n",
                "first_round_tut_sample_excel_path = Path(f'./data/first_round_tutorial_sample_no_dupl_comments_size_{tutorial_sample_size}.xlsx')\n",
                "tutorial_sample_df = sample_and_persist_df(comments_df, tutorial_sample_size, first_round_tut_sample_excel_path)\n",
                "\n",
                "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
                "    display(tutorial_sample_df)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Stratified Sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# shuffle so we have a fair chance of getting at least 1 sample per project labeled\n",
                "# NOTE: random state was not passed initially, so we cannot possibly retrieve same sample anymore\n",
                "# as we used for labeling..\n",
                "sample_excel_path = Path(f'./data/no_context_no_dupl_sample_comments_set_seed_size_{len(stratified_df)}.xlsx')\n",
                "stratified_df = stratified_df.sample(frac=1, random_state=2357295).reset_index(drop=True)\n",
                "startified_shuff_df = sample_and_persist_df(stratified_df, 1, sample_excel_path)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Context reference generation and persistence\n",
                "---\n",
                "## Second (context) Tutorial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\twanv\\AppData\\Local\\Temp\\ipykernel_22888\\2659528413.py:32: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  context_df['COMM_COMMIT_URL'] = get_commit_diff_comment_urls(\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>ID</th>\n",
                            "      <th>FILE_PATH</th>\n",
                            "      <th>COMM_TYPE</th>\n",
                            "      <th>COMM_DATE</th>\n",
                            "      <th>COMM_COMMIT_URL</th>\n",
                            "      <th>HUNK_OLD_LINE</th>\n",
                            "      <th>HUNK_NEW_LINE</th>\n",
                            "      <th>CONTENT</th>\n",
                            "      <th>PROJECT</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>103</th>\n",
                            "      <td>645f91f2a7350c5b68cd73f6</td>\n",
                            "      <td>nifi-nar-bundles/nifi-scripting-bundle/nifi-sc...</td>\n",
                            "      <td>GROUPED_LINE</td>\n",
                            "      <td>2016-08-17 18:06:18</td>\n",
                            "      <td>https://github.com/apache/nifi/blob/a5261914fb...</td>\n",
                            "      <td>215</td>\n",
                            "      <td>232</td>\n",
                            "      <td>If the script provides a Processor, call its ...</td>\n",
                            "      <td>nifi</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>110</th>\n",
                            "      <td>645f9211a7350c5b68ced209</td>\n",
                            "      <td>src/main/java/org/apache/directory/fortress/co...</td>\n",
                            "      <td>BLOCK</td>\n",
                            "      <td>2016-10-09 01:58:45</td>\n",
                            "      <td>https://github.com/apache/directory-fortress-c...</td>\n",
                            "      <td>745</td>\n",
                            "      <td>735</td>\n",
                            "      <td>* Ensure the paSet is present and name is safe.</td>\n",
                            "      <td>directory-fortress-core</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>111</th>\n",
                            "      <td>645f91eca7350c5b68cd5562</td>\n",
                            "      <td>nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-...</td>\n",
                            "      <td>GROUPED_LINE</td>\n",
                            "      <td>2017-12-18 18:23:58</td>\n",
                            "      <td>https://github.com/apache/nifi/commit/fc73c609...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Only apply the function when the element is t...</td>\n",
                            "      <td>nifi</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>115</th>\n",
                            "      <td>645f910ca7350c5b68c7ab76</td>\n",
                            "      <td>storage-hbase/src/main/java/org/apache/kylin/s...</td>\n",
                            "      <td>GROUPED_LINE</td>\n",
                            "      <td>2016-03-10 08:42:41</td>\n",
                            "      <td>https://github.com/apache/kylin/blob/0ba5881aa...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>create htable if it doesn't exist</td>\n",
                            "      <td>kylin</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>117</th>\n",
                            "      <td>645f9455a7350c5b68d8f5da</td>\n",
                            "      <td>curator-framework/src/main/java/org/apache/cur...</td>\n",
                            "      <td>GROUPED_LINE</td>\n",
                            "      <td>2019-03-03 20:30:21</td>\n",
                            "      <td>https://github.com/apache/curator/blob/1552755...</td>\n",
                            "      <td>57</td>\n",
                            "      <td>225</td>\n",
                            "      <td>Just calling inflater.needsInput() doesn't wo...</td>\n",
                            "      <td>curator</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                           ID  \\\n",
                            "103  645f91f2a7350c5b68cd73f6   \n",
                            "110  645f9211a7350c5b68ced209   \n",
                            "111  645f91eca7350c5b68cd5562   \n",
                            "115  645f910ca7350c5b68c7ab76   \n",
                            "117  645f9455a7350c5b68d8f5da   \n",
                            "\n",
                            "                                             FILE_PATH     COMM_TYPE  \\\n",
                            "103  nifi-nar-bundles/nifi-scripting-bundle/nifi-sc...  GROUPED_LINE   \n",
                            "110  src/main/java/org/apache/directory/fortress/co...         BLOCK   \n",
                            "111  nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-...  GROUPED_LINE   \n",
                            "115  storage-hbase/src/main/java/org/apache/kylin/s...  GROUPED_LINE   \n",
                            "117  curator-framework/src/main/java/org/apache/cur...  GROUPED_LINE   \n",
                            "\n",
                            "              COMM_DATE                                    COMM_COMMIT_URL  \\\n",
                            "103 2016-08-17 18:06:18  https://github.com/apache/nifi/blob/a5261914fb...   \n",
                            "110 2016-10-09 01:58:45  https://github.com/apache/directory-fortress-c...   \n",
                            "111 2017-12-18 18:23:58  https://github.com/apache/nifi/commit/fc73c609...   \n",
                            "115 2016-03-10 08:42:41  https://github.com/apache/kylin/blob/0ba5881aa...   \n",
                            "117 2019-03-03 20:30:21  https://github.com/apache/curator/blob/1552755...   \n",
                            "\n",
                            "     HUNK_OLD_LINE  HUNK_NEW_LINE  \\\n",
                            "103            215            232   \n",
                            "110            745            735   \n",
                            "111              0              1   \n",
                            "115              0              1   \n",
                            "117             57            225   \n",
                            "\n",
                            "                                               CONTENT  \\\n",
                            "103   If the script provides a Processor, call its ...   \n",
                            "110    * Ensure the paSet is present and name is safe.   \n",
                            "111   Only apply the function when the element is t...   \n",
                            "115                  create htable if it doesn't exist   \n",
                            "117   Just calling inflater.needsInput() doesn't wo...   \n",
                            "\n",
                            "                     PROJECT  \n",
                            "103                     nifi  \n",
                            "110  directory-fortress-core  \n",
                            "111                     nifi  \n",
                            "115                    kylin  \n",
                            "117                  curator  "
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# # retrieve all samples from tutorial df that are labeled as \"needs context\"\n",
                "# # to use as tutorial sample for labeling samples with context\n",
                "# satd_labeled_tutorial_sample_path = Path('./data/SATD label sheet for tutorial.xlsx')\n",
                "# labeled_tut_sample_df = pd.read_excel(satd_labeled_tutorial_sample_path, sheet_name='Comments Labeled',\n",
                "#                                        usecols='D',\n",
                "#                                          na_values='',\n",
                "#                                            nrows=len(tutorial_sample_df), ).fillna('nan')\n",
                "# tutorial_sample_reset_idx_df = tutorial_sample_df.reset_index(drop=True)\n",
                "# context_df = tutorial_sample_reset_idx_df[labeled_tut_sample_df.iloc[:,0].str.contains(\"needs context\")]\n",
                "# context_df.tail()\n",
                "\n",
                "satd_labeled_tutorial_sample_path = Path('./data/SATD label sheet for tutorial.xlsx')\n",
                "sec_tut_context_df = create_context_df(first_round_tut_sample_excel_path, satd_labeled_tutorial_sample_path, 'D', context_label='needs context')\n",
                "sec_tut_context_df.tail()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# persist context df\n",
                "context_lab_tut_sample_excel_path = Path(f'./data/second_round_tutorial_sample_size_{len(sec_tut_context_df)}.xlsx')\n",
                "sec_tut_context_df.to_excel(context_lab_tut_sample_excel_path, index=False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Context Labeling Round"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# just add another column to the aggregated labeling sheet where you choose a final label\n",
                "# so you dont have to set all 3 labels to same thing in all 3 different sheets\n",
                "# and so context generation can be same as for tutorial.\n",
                "\n",
                "satd_labeled_first_round_sample_path = Path('insert path to first round excell file')\n",
                "# TODO need to set length of the excell files being read to length of the final label column (G?)?\n",
                "# should actually not be a problem.. because gets filtered on final label column anyways and non labeled\n",
                "# will be filtered out?\n",
                "\n",
                "# add context column to all 3 label sheets? just have another label sheet context and refer to this commit url column\n",
                "# should be enough context? Check with tutorial.\n",
                "\n",
                "# TODO check also the second tutorial commit urls go through all.\n",
                "# they are now all filled but stil lots of blobs..\n",
                "\n",
                "# also can use both same dataframe because we filter on one?\n",
                "first_rnd_context_df = create_context_df(satd_labeled_first_round_sample_path, satd_labeled_first_round_sample_path, 'G', context_label='needs context')\n",
                "first_rnd_context_df.tail()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# persist context df\n",
                "context_lab_first_round_sample_excel_path = Path(f'./data/first_round_context_sample_size_{len(first_rnd_context_df)}.xlsx')\n",
                "first_rnd_context_df.to_excel(context_lab_first_round_sample_excel_path, index=False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inter-rater Agreement\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.12344113295286419"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from cmath import nan\n",
                "from typing import Any, Union\n",
                "import krippendorff\n",
                "\n",
                "def label_converter(label: str) -> int:\n",
                "    if label == 'satd':\n",
                "        return 1\n",
                "    elif label == 'non-satd':\n",
                "        return 0\n",
                "    else:\n",
                "        return nan\n",
                "\n",
                "satd_labeled_sample_path = Path('./data/SATD data quality check.xlsx')\n",
                "labeled_sample_df = pd.read_excel(satd_labeled_sample_path, sheet_name='Comments Labeled',\n",
                "    usecols='D:F',\n",
                "    na_values=\"...\",\n",
                "    converters={0: label_converter, 1: label_converter, 2: label_converter},\n",
                "    nrows=len(stratified_df))\n",
                "\n",
                "reliability_data = [labeled_sample_df[column].tolist() for column in labeled_sample_df]\n",
                "\n",
                "# gives back nan if whole row of one labeler is nan\n",
                "krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>labeler 1 (Nathan)</th>\n",
                            "      <th>labeler 2 (Alexander)</th>\n",
                            "      <th>labeler 3 (Twan)</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>non-satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>non-satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>non-satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>91</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>satd</td>\n",
                            "      <td>satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>92</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>non-satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>93</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>94</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>non-satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>95</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>non-satd</td>\n",
                            "      <td>non-satd</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>96 rows × 3 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    labeler 1 (Nathan) labeler 2 (Alexander) labeler 3 (Twan)\n",
                            "0                  NaN              non-satd         non-satd\n",
                            "1                  NaN              non-satd         non-satd\n",
                            "2                  NaN                  satd         non-satd\n",
                            "3                  NaN                  satd         non-satd\n",
                            "4                  NaN              non-satd         non-satd\n",
                            "..                 ...                   ...              ...\n",
                            "91                 NaN                  satd             satd\n",
                            "92                 NaN              non-satd         non-satd\n",
                            "93                 NaN                  satd         non-satd\n",
                            "94                 NaN              non-satd         non-satd\n",
                            "95                 NaN              non-satd         non-satd\n",
                            "\n",
                            "[96 rows x 3 columns]"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "labeled_sample_df\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[WDM] - Downloading: 100%|██████████| 6.81M/6.81M [00:00<00:00, 27.9MB/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "https://github.com/apache/commons-rdf/commit/92998b329182724789f44272f60538dc195b8df3#diff-dac69938e4093eccc15dd1907659090c2b72963a19e747a55d0f38d90e46e556R495\n"
                    ]
                }
            ],
            "source": [
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.13 64-bit (windows store)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "b822c9c47dc7b5bdd28b843ed84d7054d64306828e1ed0cf24cd4ee05ee5bade"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
